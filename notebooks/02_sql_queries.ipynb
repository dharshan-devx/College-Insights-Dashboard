{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62707cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.13.5)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# College Insights Dashboard: SQL Queries (02_sql_queries.ipynb)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates the use of SQL to retrieve key insights from our dataset. We'll leverage a powerful Python library, `sqlite3`, to create an in-memory database from our pandas DataFrame. This approach allows us to write and execute SQL queries without needing a separate database server, which is excellent for a project like this.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup and Data Loading\\n\",\n",
    "    \"\\n\",\n",
    "    \"First, we'll load the necessary libraries and the cleaned data from our `src/` directory. This ensures we are working with the most up-to-date and prepared dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import sqlite3\\n\",\n",
    "    \"import logging\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set up logging\\n\",\n",
    "    \"logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Assume we have a function in src/ to load the clean DataFrame\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..') # Add the parent directory to the path to import from 'src'\\n\",\n",
    "    \"from src.load_data import load_all_data\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load the cleaned and merged DataFrame\\n\",\n",
    "    \"df = load_all_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"if df is not None:\\n\",\n",
    "    \"    logging.info(\\\"DataFrame loaded successfully. Creating in-memory database...\\\")\\n\",\n",
    "    \"    # Create an in-memory SQLite database connection\\n\",\n",
    "    \"    conn = sqlite3.connect(':memory:')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Write the pandas DataFrame to a SQL table named 'student_data'\\n\",\n",
    "    \"    df.to_sql('student_data', conn, index=False, if_exists='replace')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    logging.info(\\\"In-memory database table 'student_data' created.\\\")\\n\",\n",
    "    \"    print(\\\"\\\\nFirst 5 rows of the SQL table:\\\\n\\\")\\n\",\n",
    "    \"    display(pd.read_sql_query(\\\"SELECT * FROM student_data LIMIT 5;\\\", conn))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    logging.error(\\\"Could not load data. Please check the `data` directory and `src/load_data.py`.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. SQL Queries for Key Insights\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now we will run several advanced SQL queries to answer specific business questions related to college performance. This demonstrates your ability to think critically and translate requirements into database operations.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Query 1: Top 5 Students by Average Marks\\n\",\n",
    "    \"This query identifies the top-performing students across all subjects, ordered by their average score.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"query_top_students = \\\"\\\"\\\"\\n\",\n",
    "    \"    SELECT \\n\",\n",
    "    \"        student_name,\\n\",\n",
    "    \"        department,\\n\",\n",
    "    \"        AVG(marks) AS avg_marks\\n\",\n",
    "    \"    FROM \\n\",\n",
    "    \"        student_data\\n\",\n",
    "    \"    GROUP BY \\n\",\n",
    "    \"        student_name, department\\n\",\n",
    "    \"    ORDER BY \\n\",\n",
    "    \"        avg_marks DESC\\n\",\n",
    "    \"    LIMIT 5;\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"top_students_df = pd.read_sql_query(query_top_students, conn)\\n\",\n",
    "    \"print(\\\"Top 5 Students by Average Marks:\\\")\\n\",\n",
    "    \"display(top_students_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Query 2: Pass Percentage by Subject\\n\",\n",
    "    \"This query calculates the pass percentage for each subject, which is a key metric for faculty to understand subject difficulty and student performance trends.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"query_pass_percentage = \\\"\\\"\\\"\\n\",\n",
    "    \"    SELECT \\n\",\n",
    "    \"        subject_name,\\n\",\n",
    "    \"        (SUM(CASE WHEN pass_status = 'Pass' THEN 1 ELSE 0 END) * 100.0) / COUNT(*) AS pass_rate_percent\\n\",\n",
    "    \"    FROM \\n\",\n",
    "    \"        student_data\\n\",\n",
    "    \"    GROUP BY \\n\",\n",
    "    \"        subject_name\\n\",\n",
    "    \"    ORDER BY \\n\",\n",
    "    \"        pass_rate_percent DESC;\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"pass_percentage_df = pd.read_sql_query(query_pass_percentage, conn)\\n\",\n",
    "    \"print(\\\"Pass Percentage by Subject:\\\")\\n\",\n",
    "    \"display(pass_percentage_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Query 3: Identify 'At-Risk' Students (Low Attendance)\\n\",\n",
    "    \"This query pinpoints students with an attendance percentage below a predefined threshold (e.g., 75%), which is a common policy in many institutions. Identifying these students early is critical for intervention.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"query_at_risk_students = \\\"\\\"\\\"\\n\",\n",
    "    \"    SELECT DISTINCT\\n\",\n",
    "    \"        student_name, \\n\",\n",
    "    \"        department, \\n\",\n",
    "    \"        attendance AS attendance_percentage\\n\",\n",
    "    \"    FROM \\n\",\n",
    "    \"        student_data\\n\",\n",
    "    \"    WHERE \\n\",\n",
    "    \"        attendance < 75\\n\",\n",
    "    \"    ORDER BY\\n\",\n",
    "    \"        attendance_percentage ASC;\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"at_risk_students_df = pd.read_sql_query(query_at_risk_students, conn)\\n\",\n",
    "    \"print(\\\"Students with Attendance < 75%:\\\")\\n\",\n",
    "    \"display(at_risk_students_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if at_risk_students_df.empty:\\n\",\n",
    "    \"    print(\\\"\\\\nNo students found with attendance below 75% in the current dataset.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook showcases how to leverage SQL for data querying and analysis. The ability to write and execute these queries demonstrates a strong understanding of relational data, a skill that is highly valued by recruiters. The insights gained here will be used to inform our visualizations and dashboard features.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Close the database connection when done\\n\",\n",
    "    \"if 'conn' in locals() and conn:\\n\",\n",
    "    \"    conn.close()\\n\",\n",
    "    \"    logging.info(\\\"Database connection closed.\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
